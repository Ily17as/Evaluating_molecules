{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nikita/edu/competitions/admet\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GINConv, GATv2Conv, GCNConv, Sequential\n",
    "from torch_geometric.nn.aggr import AttentionalAggregation, MeanAggregation\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features.append(atom.GetAtomicNum())\n",
    "\n",
    "    edges = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edges.append((i, j))\n",
    "        edges.append((j, i))\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(atom_features, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train_admet.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"data/test_data.csv\", index_col=0)\n",
    "sample = pd.read_csv(\"data/sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trains = []\n",
    "df_vals = []\n",
    "df_tests = []\n",
    "\n",
    "properties = df_train.property.unique()\n",
    "for prop in properties:\n",
    "    segment = df_train[df_train[\"property\"] == prop]\n",
    "    train, val = train_test_split(\n",
    "        segment, test_size=0.2, random_state=75, stratify=segment.Y\n",
    "    )\n",
    "    df_trains.append(train)\n",
    "    df_vals.append(val)\n",
    "    df_tests.append(df_test[df_test[\"property\"] == prop])\n",
    "\n",
    "sampler = RandomOverSampler(random_state=0)\n",
    "\n",
    "for i in range(len(df_trains)):\n",
    "    df_trains[i] = sampler.fit_resample(df_trains[i], df_trains[i].Y)[0]\n",
    "    df_vals[i] = sampler.fit_resample(df_vals[i], df_vals[i].Y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:03:02] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "train_datasets = []\n",
    "val_datasets = []\n",
    "\n",
    "for i in range(len(df_trains)):\n",
    "    train_data = []\n",
    "    for j, row in df_trains[i].iterrows():\n",
    "        features = smiles_to_graph(row[\"Drug\"])\n",
    "        target = row[\"Y\"]\n",
    "\n",
    "        features.y = target\n",
    "        train_data.append(features)\n",
    "    train_datasets.append(train_data)\n",
    "\n",
    "    val_data = []\n",
    "    for j, row in df_vals[i].iterrows():\n",
    "        features = smiles_to_graph(row[\"Drug\"])\n",
    "        target = row[\"Y\"]\n",
    "\n",
    "        features.y = target\n",
    "        val_data.append(features)\n",
    "    val_datasets.append(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/edu/competitions/admet/.conda/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_dataloaders = []\n",
    "val_dataloaders = []\n",
    "\n",
    "for i in range(len(train_datasets)):\n",
    "    train_dataloaders.append(DataLoader(train_datasets[i], batch_size=32, shuffle=True))\n",
    "    val_dataloaders.append(DataLoader(val_datasets[i], batch_size=32, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeCrusher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=100, embedding_dim=128)\n",
    "        self.gnn = Sequential(\n",
    "            \"x, edge_index, batch\",\n",
    "            [\n",
    "                (GCNConv(128, 256), \"x, edge_index -> x\"),\n",
    "                nn.SiLU(),\n",
    "                (GCNConv(256, 256), \"x, edge_index -> x\"),\n",
    "                nn.SiLU(),\n",
    "                (GCNConv(256, 512), \"x, edge_index -> x\"),\n",
    "                nn.SiLU(),\n",
    "                (GCNConv(512, 512), \"x, edge_index -> x\"),\n",
    "                nn.SiLU(),\n",
    "                (GCNConv(512, 1024), \"x, edge_index -> x\"),\n",
    "                nn.SiLU(),\n",
    "                (GCNConv(1024, 1024), \"x, edge_index -> x\"),\n",
    "                nn.SiLU(),\n",
    "                (\n",
    "                    MeanAggregation(),\n",
    "                    \"x, batch -> x\",\n",
    "                ),\n",
    "                nn.SiLU(),\n",
    "                (nn.Linear(1024, 1), \"x -> x\"),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def compute_loss(self, pred, target):\n",
    "        return F.binary_cross_entropy_with_logits(pred, target)\n",
    "    \n",
    "    def compute_auc(self, pred, target):\n",
    "        return roc_auc_score(target, pred)\n",
    "\n",
    "    def forward(self, data: Data):\n",
    "        x = data.x.view(-1).to(torch.long)\n",
    "        idx = data.edge_index\n",
    "        batch = data.batch\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = self.gnn(x, idx, batch)\n",
    "\n",
    "        return x.view(-1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, data: Data):\n",
    "        return torch.sigmoid(self.forward(data))\n",
    "\n",
    "    def train(self, epochs, train_dataloader, val_dataloader):\n",
    "        for epoch in range(epochs):\n",
    "            train_loss_buffer = deque(maxlen=4)\n",
    "            train_loop = tqdm(train_dataloader, desc=f\"Train epoch {epoch}\")\n",
    "            for data in train_loop:\n",
    "                data = data.to(self.device)\n",
    "                target = data.y.to(torch.float32)\n",
    "                pred = self.forward(data)\n",
    "                loss = self.compute_loss(pred, target)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss_buffer.append(loss.item())\n",
    "                train_loop.set_postfix(loss=np.mean(train_loss_buffer))\n",
    "\n",
    "            val_loss_buffer = list()\n",
    "            val_loop = tqdm(val_dataloader, desc=f\"Val epoch {epoch}\")\n",
    "            all_targets = []\n",
    "            all_preds = []\n",
    "            with torch.no_grad():\n",
    "                for data in val_loop:\n",
    "                    data = data.to(self.device)\n",
    "                    target = data.y.to(torch.float32)\n",
    "                    pred = self.forward(data)\n",
    "                    all_targets.append(target.detach().cpu().numpy())\n",
    "                    all_preds.append(pred.detach().cpu().numpy())\n",
    "                    loss = self.compute_loss(pred, target)\n",
    "                    val_loss_buffer.append(loss.item())\n",
    "                    val_loop.set_postfix(loss=np.mean(val_loss_buffer))\n",
    "\n",
    "            all_preds = np.concatenate(all_preds, axis=0).reshape(-1)\n",
    "            all_targets = np.concatenate(all_targets, axis=0).reshape(-1)\n",
    "            print(self.compute_auc(all_preds, all_targets))\n",
    "            val_loop.set_postfix(loss=self.compute_auc(all_preds, all_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0:   0%|          | 0/138 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0: 100%|██████████| 138/138 [00:01<00:00, 91.94it/s, loss=0.665]\n",
      "Val epoch 0: 100%|██████████| 35/35 [00:00<00:00, 183.97it/s, loss=0.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6998775861163622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 100%|██████████| 138/138 [00:01<00:00, 99.21it/s, loss=0.639] \n",
      "Val epoch 1: 100%|██████████| 35/35 [00:00<00:00, 182.41it/s, loss=0.632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7090586273892039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|██████████| 138/138 [00:01<00:00, 98.88it/s, loss=0.629]\n",
      "Val epoch 2: 100%|██████████| 35/35 [00:00<00:00, 183.16it/s, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7099168373240916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3: 100%|██████████| 138/138 [00:01<00:00, 99.35it/s, loss=0.649]\n",
      "Val epoch 3: 100%|██████████| 35/35 [00:00<00:00, 181.50it/s, loss=0.658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6739606306448225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 4: 100%|██████████| 138/138 [00:01<00:00, 98.09it/s, loss=0.67] \n",
      "Val epoch 4: 100%|██████████| 35/35 [00:00<00:00, 176.41it/s, loss=0.618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7223108328082336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 5: 100%|██████████| 138/138 [00:01<00:00, 98.14it/s, loss=0.609]\n",
      "Val epoch 5: 100%|██████████| 35/35 [00:00<00:00, 181.79it/s, loss=0.623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7239123871035498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 6: 100%|██████████| 138/138 [00:01<00:00, 98.43it/s, loss=0.622]\n",
      "Val epoch 6: 100%|██████████| 35/35 [00:00<00:00, 168.99it/s, loss=0.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7304006511237134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 7: 100%|██████████| 138/138 [00:01<00:00, 97.73it/s, loss=0.688]\n",
      "Val epoch 7: 100%|██████████| 35/35 [00:00<00:00, 176.84it/s, loss=0.606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7327028854232305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 8: 100%|██████████| 138/138 [00:01<00:00, 97.54it/s, loss=0.641]\n",
      "Val epoch 8: 100%|██████████| 35/35 [00:00<00:00, 168.52it/s, loss=0.633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7230049490653224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 9: 100%|██████████| 138/138 [00:01<00:00, 98.15it/s, loss=0.59] \n",
      "Val epoch 9: 100%|██████████| 35/35 [00:00<00:00, 156.54it/s, loss=0.614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7319250813904641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 10: 100%|██████████| 138/138 [00:01<00:00, 98.75it/s, loss=0.675]\n",
      "Val epoch 10: 100%|██████████| 35/35 [00:00<00:00, 177.69it/s, loss=0.619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7311160995589161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 11: 100%|██████████| 138/138 [00:01<00:00, 97.28it/s, loss=0.802]\n",
      "Val epoch 11: 100%|██████████| 35/35 [00:00<00:00, 178.37it/s, loss=0.604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7363572516278093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 12: 100%|██████████| 138/138 [00:01<00:00, 98.18it/s, loss=0.658]\n",
      "Val epoch 12: 100%|██████████| 35/35 [00:00<00:00, 173.69it/s, loss=0.615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7389121901911363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 13: 100%|██████████| 138/138 [00:01<00:00, 98.17it/s, loss=0.62] \n",
      "Val epoch 13: 100%|██████████| 35/35 [00:00<00:00, 175.31it/s, loss=0.615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7393109378281874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 14: 100%|██████████| 138/138 [00:01<00:00, 97.13it/s, loss=0.661]\n",
      "Val epoch 14: 100%|██████████| 35/35 [00:00<00:00, 176.27it/s, loss=0.621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7295473639991599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 15: 100%|██████████| 138/138 [00:01<00:00, 97.18it/s, loss=0.66] \n",
      "Val epoch 15: 100%|██████████| 35/35 [00:00<00:00, 179.27it/s, loss=0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7352299280613316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 16: 100%|██████████| 138/138 [00:01<00:00, 97.07it/s, loss=0.663]\n",
      "Val epoch 16: 100%|██████████| 35/35 [00:00<00:00, 156.10it/s, loss=0.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7406351738080236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 17: 100%|██████████| 138/138 [00:01<00:00, 95.92it/s, loss=0.702]\n",
      "Val epoch 17: 100%|██████████| 35/35 [00:00<00:00, 176.36it/s, loss=0.603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7405974322621298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 18: 100%|██████████| 138/138 [00:01<00:00, 96.84it/s, loss=0.63] \n",
      "Val epoch 18: 100%|██████████| 35/35 [00:00<00:00, 180.69it/s, loss=0.616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7225881511237136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 19: 100%|██████████| 138/138 [00:01<00:00, 96.10it/s, loss=0.646]\n",
      "Val epoch 19: 100%|██████████| 35/35 [00:00<00:00, 174.74it/s, loss=0.603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7496980676328502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 20:  61%|██████    | 84/138 [00:00<00:00, 97.02it/s, loss=0.648]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m MoleculeCrusher()\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 62\u001b[0m, in \u001b[0;36mMoleculeCrusher.train\u001b[0;34m(self, epochs, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     60\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     61\u001b[0m target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 62\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(pred, target)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[17], line 47\u001b[0m, in \u001b[0;36mMoleculeCrusher.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     44\u001b[0m batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mbatch\n\u001b[1;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m---> 47\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/edu/competitions/admet/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/edu/competitions/admet/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.sequential_c83bb4_ylczud_l.py:55\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_8(x, edge_index)\n\u001b[1;32m     54\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_9(x)\n\u001b[0;32m---> 55\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_11(x)\n\u001b[1;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_12(x, batch)\n",
      "File \u001b[0;32m~/edu/competitions/admet/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/edu/competitions/admet/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/edu/competitions/admet/.conda/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/edu/competitions/admet/.conda/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:99\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 99\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    104\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/edu/competitions/admet/.conda/lib/python3.11/site-packages/torch_geometric/utils/loop.py:651\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    647\u001b[0m     is_undirected \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mis_undirected\n\u001b[1;32m    649\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m edge_index[:, mask]\n\u001b[0;32m--> 651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_scripting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[1;32m    652\u001b[0m     edge_index\u001b[38;5;241m.\u001b[39m_is_undirected \u001b[38;5;241m=\u001b[39m is_undirected\n\u001b[1;32m    654\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_index, loop_index], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/edu/competitions/admet/.conda/lib/python3.11/site-packages/torch/_jit_internal.py:1130\u001b[0m, in \u001b[0;36mis_scripting\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m7\u001b[39m):\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcastingList\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m BroadcastingList1\n\u001b[0;32m-> 1130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_scripting\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m    Function that returns True when in compilation and False otherwise. This\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;124;03m    is useful especially with the @unused decorator to leave code in your\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;124;03m              return unsupported_linear_op(x)\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MoleculeCrusher()\n",
    "model.to(\"cuda\")\n",
    "model.train(epochs=500, train_dataloader=train_dataloaders[0], val_dataloader=val_dataloaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(epochs=4000, train_dataloader=train_dataloaders[0], val_dataloader=val_dataloaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "val_sample = next(iter(val_dataloaders[0])).to(model.device)\n",
    "pred = model.predict(val_sample)\n",
    "pred = (pred >= 0.5).to(torch.float32)\n",
    "print(pred.to(torch.long))\n",
    "print(val_sample.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
